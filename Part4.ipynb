{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we extend the HMM to have second-order dependencies by modifying the Viterbi algorithm.\n",
    "\n",
    "The logic is as follows:\n",
    "Our Viterbi algorithm thus far uses a first-order assumption, only including the probability of the previous state in the calculation of the likelihood of the current state. We want to now include the *previous two states* in our calculation.\n",
    "\n",
    "The algorithm can still be designed via dynamic programming. However, runtime is further multiplied by (number of states) due to the additional layer of multiplication, for a total runtime of $O(T \\times |S|^3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "# from tqdm import tqdm, trange\n",
    "from tqdm import tqdm_notebook as tqdm, tnrange as trange\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk stopwords\n",
    "stopwords = {'it', 'before', \"you're\", 'wouldn', \"hasn't\", 'again', 'just', \"you'd\", 'only', \"wouldn't\", \"isn't\", 'no', 'yourself', 'them', 'in', 's', \"aren't\", 'because', 'ourselves', 'more', \"couldn't\", \"shan't\", \"shouldn't\", 'shan', 't', 'needn', \"hadn't\", 'both', 'such', 'below', 'out', 'my', \"haven't\", 'there', 'off', 'few', 'against', 'each', 'can', 'yourselves', 'some', 'further', 'if', 'under', 'over', 'theirs', 'his', 'herself', 'been', 'her', 'than', \"you've\", 'into', 'have', 'aren', 'and', 'then', 'whom', 'having', 'the', 'by', 'itself', 'him', 'up', 'be', \"wasn't\", 'me', 'of', 'haven', 'they', \"mightn't\", 'our', 'are', 'how', \"weren't\", 'couldn', 'too', \"should've\", 'until', 'weren', \"that'll\", 'a', 'when', \"doesn't\", 'which', 'here', 'was', 'hers', 'ain', 'mightn', 'those', 'himself', 'or', 'while', 'i', 'yours', 'from', 'once', 'after', 'does', 'its', 'to', 'you', 'myself', 'don', 'shouldn', 'most', 'that', 'mustn', 'same', \"it's\", 'what', 'any', 'did', 'isn', 'she', 'these', 'with', 'during', \"needn't\", 'your', 'their', 'being', 'on', 'above', 've', 'won', 'down', \"she's\", 're', 'this', 'do', 'hasn', 'had', 'so', 'other', 'an', 'were', 'hadn', 'themselves', 'will', 'as', 'for', 'at', 'd', 'm', 'but', 'ma', 'didn', 'll', 'not', \"won't\", 'ours', 'who', 'through', 'all', 'now', 'o', 'nor', \"mustn't\", \"you'll\", 'where', 'doesn', 'y', 'doing', 'why', 'between', \"didn't\", 'he', 'we', 'wasn', 'has', 'very', \"don't\", 'own', 'about', 'is', 'should', 'am'}\n",
    "len(stopwords)\n",
    "re_punc = r'^[^a-zA-Z0-9]+$'\n",
    "re_hash = r'^#'\n",
    "re_at = r'^@'\n",
    "re_num = r'\\d'  # just remove all words with numbers\n",
    "re_url = r'(^http:|\\.com$)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(w):\n",
    "    w = w.strip()\n",
    "    if w in stopwords:\n",
    "        return '#STOP#'\n",
    "    if re.match(re_punc, w):\n",
    "        return '#PUNC#'\n",
    "    if re.match(re_hash, w):\n",
    "        return '#HASH#'\n",
    "    if re.match(re_at, w):\n",
    "        return '#AT#'\n",
    "    if re.match(re_num, w):\n",
    "        return '#NUM#'\n",
    "    if re.match(re_url, w):\n",
    "        return '#URL#'\n",
    "    return w.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions\n",
    "We train the emissions matrix by using maximum likelihood estimation:\n",
    "\n",
    "$$ e(x|y) = \\frac{Count(x->y)}{Count(y)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The behavior of the emissions matrix is the same - we use the same function as used in Part 3\n",
    "def learn_emissions(train_filename):\n",
    "    ''' Learns emissions parameters from data and returns them as a nested dictionary '''\n",
    "    with open(train_filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    observations = set()\n",
    "    # Track emission counts\n",
    "    emissions = {} # Where key is y, and value is a dictionary of emissions x from y with their frequency\n",
    "\n",
    "    # Learn from data\n",
    "    for line in tqdm(lines, desc='Emissions'):\n",
    "        data_split = line.strip().rsplit(' ', 1)\n",
    "\n",
    "        # Only process valid lines\n",
    "        if len(data_split) == 2:\n",
    "            obs, state = data_split\n",
    "            obs = clean_word(obs)\n",
    "            observations.add(obs)\n",
    "\n",
    "            # Track this emission\n",
    "            if state in emissions:\n",
    "                current_emissions = emissions[state]\n",
    "            else:\n",
    "                current_emissions = defaultdict(int)\n",
    "                \n",
    "            current_emissions[obs] += 1\n",
    "            emissions[state] = current_emissions # Update\n",
    "    \n",
    "    emission_counts = {k: sum(emissions[k].values()) for k in emissions}\n",
    "    return emissions, emission_counts, observations\n",
    "\n",
    "\n",
    "def get_emission_parameters(emissions, emission_counts, observations, x, y, k=1):\n",
    "    ''' Returns the MLE of the emission parameters based on the emissions dictionary '''\n",
    "    if y not in emissions:  # edge case: no records of emission from this state\n",
    "        return 0\n",
    "    state_data = emissions[y]\n",
    "    count_y = emission_counts[y] #sum(state_data.values()) # Denominator\n",
    "    \n",
    "    if x not in observations:  # edge case: no records of emission of this word\n",
    "        count_y_x = k\n",
    "    else:\n",
    "        count_y_x = state_data[x]\n",
    "    \n",
    "    e = count_y_x / (count_y + k)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_transitions(train_filename):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing (key, value) where\n",
    "        key: (t, u, v)\n",
    "        value: Count(t, u, v)\n",
    "    \"\"\"\n",
    "    with open(train_filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    transitions = defaultdict(int)\n",
    "    prev_prev_state = 'PRESTART'\n",
    "    prev_state = 'START'\n",
    "    # avoid excessive indentations\n",
    "    for line in tqdm(lines, desc='Transitions'):\n",
    "        data_split = line.strip().rsplit(' ', 1)\n",
    "        \n",
    "        # line breaks -> new sequence\n",
    "        if len(data_split) < 2:\n",
    "            transitions[(prev_prev_state, prev_state, 'STOP')] += 1\n",
    "            prev_prev_state = 'PRESTART'\n",
    "            prev_state = 'START'\n",
    "            continue\n",
    "\n",
    "        obs, curr_state = data_split\n",
    "        transitions[(prev_prev_state, prev_state, curr_state)] += 1\n",
    "        prev_prev_state = prev_state\n",
    "        prev_state = curr_state\n",
    "        \n",
    "    # count number of 'from' states\n",
    "    transition_counts = defaultdict(int)\n",
    "    for (t, u, v), counts in transitions.items():\n",
    "        transition_counts[(t, u)] += counts\n",
    "\n",
    "    # get all unique states\n",
    "    t, u, v = zip(*transitions)\n",
    "    states = set(t) | set(u) | set(v)\n",
    "    return transitions, transition_counts, states\n",
    "\n",
    "def get_transition_parameters(transitions, transition_counts, t, u, v):\n",
    "    if transition_counts[(t, u)] == 0:  # edge case: no records of transitions starting from (t, u)\n",
    "        return 0\n",
    "    return transitions[(t, u, v)] / transition_counts[(t, u)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the Viterbi algorithm for Part 4, to include second-order dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, e = train('EN')\n",
    "# transitions, transition_counts, states = t\n",
    "# emissions, emission_counts, observations = e\n",
    "# obs_seq = ['hello', 'my', 'name', 'is', 'rayson']\n",
    "\n",
    "# # def viterbi(transitions, transition_counts, states, emissions, emission_counts, observations, obs_seq):\n",
    "# a = lambda prev2, prev, curr: get_transition_parameters(transitions, transition_counts, prev2, prev, curr)\n",
    "# b = lambda state, out: get_emission_parameters(emissions, emission_counts, observations, y=state, x=out)\n",
    "\n",
    "# # create empty tables\n",
    "# n = len(obs_seq) + 3  # PRESTART + START + |obs_seq| + STOP\n",
    "# P = pd.DataFrame(index=states, columns=range(n)).fillna(0)  # probability table\n",
    "# B = pd.DataFrame(index=states, columns=range(n))  # backpointer table\n",
    "\n",
    "# # initialization\n",
    "# P.loc['PRESTART', 0] = 1\n",
    "# P.loc['START', 1] = 1\n",
    "\n",
    "# # recursion\n",
    "# for j in range(2, n-1):\n",
    "#     x = obs_seq[j-2]  # obs_seq starts from 0, j starts from 2\n",
    "#     for v in states:  # curr state\n",
    "#         for u in states:  # prev state\n",
    "#             for t in states: # prev_2 state\n",
    "# #                 p = P.loc[t, j-2] * P.loc[u, j-1] * a(t, u, v) * b(v, x)\n",
    "#                 p = P.loc[u, j-1] * a(t, u, v) * b(v, x)\n",
    "#                 if p > P.loc[v, j]:\n",
    "#                     P.loc[v, j] = p  # update probability\n",
    "#                     B.loc[v, j] = t + ' ' + u  # update backpointer\n",
    "\n",
    "# # termination\n",
    "# j = n - 1\n",
    "# v = 'STOP'\n",
    "# for u in states:\n",
    "#     for t in states:\n",
    "#         p = P.loc[u, j-1] * P.loc[t, j-2] * a(t, u, v)\n",
    "#         if p > P.loc[v, j]:\n",
    "#             P.loc[v, j] = p  # probability\n",
    "#             B.loc[v, j] = t + ' ' + u  # backpointer\n",
    "\n",
    "# # backtracing\n",
    "# # second order viterbi requires backpropagation keep track of the second order item, \n",
    "# # as the limited horizon assumption is now limited to *two* entries instead.\n",
    "# state_seq = ['STOP']\n",
    "# # Skip steps 2 at a time\n",
    "# for i in range(n-1, 0, -1):\n",
    "#     curr_state = state_seq[-1]\n",
    "#     B_lookup = B.loc[curr_state, i]\n",
    "#     if isinstance(B_lookup, str):\n",
    "#         prev_state = B.loc[curr_state, i].split(' ')[1]\n",
    "#         prev_prev_state = B.loc[curr_state, i].split(' ')[0]\n",
    "#     else: # edge case: no possible transition to START\n",
    "#         for j in range(int(i)):\n",
    "#             state_seq.append(('O'))\n",
    "#         break\n",
    "#     state_seq.append(prev_state)\n",
    "# state_seq = state_seq[::-1][2:-1]  # reverse and drop PRESTART, START, STOP\n",
    "# print(state_seq)\n",
    "# #     return P, B, state_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, e = train('EN')\n",
    "# transitions, transition_counts, states = t\n",
    "# emissions, emission_counts, observations = e\n",
    "# obs_seq = ['going', 'to', 'the', 'city']\n",
    "\n",
    "def viterbi(transitions, transition_counts, states, emissions, emission_counts, observations, obs_seq):\n",
    "    a = lambda prev2, prev, curr: get_transition_parameters(transitions, transition_counts, prev2, prev, curr)\n",
    "    b = lambda state, out: get_emission_parameters(emissions, emission_counts, observations, y=state, x=out)\n",
    "\n",
    "    # create empty tables\n",
    "    n = len(obs_seq) + 2  # (PRESTART + START), (START, obs_seq[0]) + ... + (obs_seq[n], STOP) \n",
    "\n",
    "    state_combis = set()\n",
    "    for u in states:\n",
    "        for v in states:\n",
    "            state_combis.add((u,v))\n",
    "    P = pd.DataFrame(index=state_combis, columns=range(n)).fillna(0)  # probability table\n",
    "    B = pd.DataFrame(index=state_combis, columns=range(n))  # backpointer table\n",
    "\n",
    "    # initialization\n",
    "    P.loc[('PRESTART', 'START'), 0] = 1\n",
    "\n",
    "    # forward recursion\n",
    "    for j in range(1, n-1):\n",
    "        x = obs_seq[j-1]  # obs_seq starts from 0, j starts from 2\n",
    "        for v in states:  # curr state\n",
    "            for u in states:  # prev state\n",
    "                for t in states: # prev_2 state\n",
    "                    p = P.loc[(t, u), j-1] * a(t, u, v) * b(v, x)\n",
    "                    if p > P.loc[(u, v), j]:\n",
    "                        P.loc[(u, v), j] = p  # update probability\n",
    "                        B.loc[(u, v), j] = t  # update backpointer - t is the grandfather\n",
    "\n",
    "    # termination\n",
    "    j = n - 1\n",
    "    v = 'STOP'\n",
    "    for u in states: # prev state\n",
    "        for t in states: # prev_2 state\n",
    "            p = P.loc[(t, u), j-1] * a(t, u, v)\n",
    "            if p > P.loc[(u, v), j]:\n",
    "                P.loc[(u, v), j] = p  # probability\n",
    "                B.loc[(u, v), j] = t  # backpointer\n",
    "\n",
    "    # backtracing\n",
    "    # second order viterbi requires backpropagation keep track of the second order item, \n",
    "    # as the limited horizon assumption is now limited to *two* entries instead.\n",
    "    state_pair = P[n-1].idxmax()\n",
    "    state_seq = []\n",
    "    for i in range(n-1, 0, -1):\n",
    "        next_state = B.loc[state_pair, i]\n",
    "        if isinstance(next_state, str):\n",
    "            state_seq.append(state_pair[1])\n",
    "            state_pair = (next_state, state_pair[0])\n",
    "        else: # edge case: no possible transition to START\n",
    "            for j in range(int(i)):\n",
    "                state_seq.append(('O'))\n",
    "            break\n",
    "    state_seq = state_seq[::-1][:-1]  # reverse and drop STOP\n",
    "    print(state_seq)\n",
    "    return P, B, state_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get P rows with any not zeros:\n",
    "# (P.loc[~(P==0).all(axis=1)])\n",
    "# To get B rows with any not NAs:\n",
    "# B.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset):\n",
    "    \"\"\"\n",
    "    Takes in dataset name, obtains transition and emission parameters.\n",
    "    \"\"\"\n",
    "    train_filename = f'data/{dataset}/train'\n",
    "    # train\n",
    "    t = learn_transitions(train_filename)\n",
    "    e = learn_emissions(train_filename)\n",
    "    return t, e\n",
    "\n",
    "\n",
    "def validate(dataset, t, e):\n",
    "    \"\"\"\n",
    "    Takes in dataset name, and HMM parameters.\n",
    "    Use HMM parameters to estimate state sequence.\n",
    "    Write state sequence to file alongside input observation sequence.\n",
    "    \"\"\"\n",
    "    val_filename = f'data/{dataset}/dev.in'\n",
    "    out_filename = f'data/{dataset}/dev.p4.out'\n",
    "\n",
    "    # validate with train parameters\n",
    "    label_sequence = lambda sentence: viterbi(*t, *e, sentence)\n",
    "    \n",
    "    # read validation file for sequence\n",
    "    with open(val_filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    sentence = []\n",
    "    result = []\n",
    "    for word in tqdm(lines, desc=dataset):\n",
    "        if word == '\\n':\n",
    "            print(sentence)\n",
    "            _, _, s = label_sequence(sentence)  # ignore tables\n",
    "            result.extend(s)\n",
    "            result.append('\\n')\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(word.strip())\n",
    "            \n",
    "    # write sequence to out file\n",
    "    with open(out_filename, 'w') as f:\n",
    "        for i in range(len(lines)):\n",
    "            word = lines[i].strip()\n",
    "            if word:\n",
    "                pred = result[i]\n",
    "                f.write(word + ' ' + pred)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a605dde8de0d4408ab23a5e6ee028eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Transitions', max=11236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de264a563324930bb0ca2cc7dc76905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Emissions', max=11236), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b0d56f354d4dacacb10a6495774a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EN', max=1520), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO', 'Saints', 'R', '.', 'Buch', 'might', 'come', 'back', 'n', 'play', 'vs', 'Seahawks', 'on', 'Sunday', '??']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['Polling', 'ends', 'in', 'Bihar', 'today', ',', 'counting', 'on', 'November', '24', 'http://toi.in/ujtwya']\n",
      "['B-ADVP', 'B-VP', 'B-PP', 'I-PP', 'B-NP', 'O', 'B-NP', 'B-PP', 'I-PP', 'B-NP', 'O']\n",
      "['Today', 'has', 'been', 'a', 'GREAT', 'day', '__AND__', 'it', 'just', 'keeps', 'getting', 'better', '!!!', 'Thank', 'You', 'Lord', '!']\n",
      "['B-ADVP', 'B-VP', 'B-PRT', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'B-ADVP', 'I-ADVP', 'B-VP', 'B-ADJP', 'I-ADJP', 'I-ADJP', 'I-ADJP', 'I-ADJP', 'I-ADJP']\n",
      "['man', 'my', 'twin', 'wanna', 'act', 'fake', 'today', 'but', 'its', 'okay', 'bcuz', 'i', 'still', 'love', 'you']\n",
      "['B-INTJ', 'B-NP', 'I-NP', 'B-VP', 'B-ADJP', 'I-ADJP', 'B-NP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-ADVP', 'B-VP', 'B-NP']\n",
      "['@iians', 'Id', 'love', 'to', 'see', 'IDWT', 'live', 'from', 'CES', '.', 'And', 'one', 'day', 'I', 'hope', 'to', 'go', 'to', 'ces', 'myself', '.']\n",
      "['B-INTJ', 'I-INTJ', 'B-NP', 'B-VP', 'I-VP', 'B-PP', 'B-VP', 'B-PP', 'I-PP', 'I-PP', 'B-NP', 'I-NP', 'I-NP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-PP', 'B-ADVP', 'I-ADVP', 'O']\n",
      "['@Team_Panic', 'omg', ',', 'i', 'wish', 'i', 'got', 'paid', 'to', 'freak', 'people', 'out', '.', 'it', \"'s\", 'so', 'funny', 'when', 'they', 'think', \"you'r\", 'serious', '.', 'noobs', '.']\n",
      "['O', 'B-INTJ', 'I-INTJ', 'B-NP', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'B-PP', 'I-PP', 'B-NP', 'I-NP', 'B-SBAR', 'B-NP', 'B-VP', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-INTJ', 'I-INTJ', 'I-INTJ']\n",
      "['fckn', 'emily', 'rodriguez', 'did', \"n't\", 'bring', 'my', 'cookies', 'today', '!!', 'lil', 'brat', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['Amazon', 'U.K.', 'Offering', 'HTC', 'Desire', 'Z', 'Unlocked', 'October', '11', ':', 'We', 'just', 'got', 'official', 'word', 'of', 'the', 'HTC', 'Desire', 'Z', 'earlier', 'in', 'Lo', '...', 'http://bit.ly/bsyz9H']\n",
      "['B-CONJP', 'I-CONJP', 'B-VP', 'I-VP', 'B-ADJP', 'I-ADJP', 'B-PP', 'I-PP', 'I-PP', 'B-NP', 'I-NP', 'B-ADVP', 'B-VP', 'B-NP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-ADVP', 'I-ADVP', 'I-ADVP', 'B-PP', 'B-ADVP', 'I-ADVP', 'O']\n",
      "['Lmao', '..', 'They', '#Hurrt', '!', 'RT', '@_sofucKENNrude', 'y', 'every', 'nigga', 'tryna', 'grow', 'they', 'hair', 'out', '.', 'should', 'of', 'did', 'that', 'a', 'long', 'time', 'ago', '.', '-_-', 'skimp', 'ass', 'braids', '.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-75e3f36d33d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d1d07227bc31>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(dataset, t, e)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d1d07227bc31>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# validate with train parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlabel_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# read validation file for sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a8a5203fb0f2>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(transitions, transition_counts, states, emissions, emission_counts, observations, obs_seq)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# prev_2 state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                         \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m  \u001b[0;31m# update probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# update backpointer - t is the grandfather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;31m# we may have a nested tuples indexer here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_nested_tuple_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_nested_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# we maybe be using a tuple to represent multiple dimensions here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_nested_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mcurrent_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1912\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no slices here, handle elsewhere'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3015\u001b[0m         \u001b[0;31m# this could be a view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m         \u001b[0;31m# but only in a single-dtyped view slicable case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_is_view\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0;34m\"\"\"Return boolean indicating if self is view of another array \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_is_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mis_view\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3814\u001b[0m         \u001b[0;34m\"\"\" return a boolean if we are a single block and are a view \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3816\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3818\u001b[0m         \u001b[0;31m# It is technically possible to figure out which blocks are views\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mis_view\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;34m\"\"\" return a boolean if I am possibly a view \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = ['EN', 'FR']\n",
    "for dataset in datasets:\n",
    "    t, e = train(dataset)\n",
    "    validate(dataset, t, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
