\relax 
\@writefile{toc}{\contentsline {section}{\numberline {2}Maximum Likelihood Estimation}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Emission Parameters Estimation}{3}}
\newlabel{sec:emissions}{{2.1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Laplace Smoothing}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Sequence Labeling}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Results}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}First-Order Hidden Markov Model}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Transition Parameters Emission}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Viterbi Algorithm}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Initialization}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Recursion}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Backtracking}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Results}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Second-Order Hidden Markov Model}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Design Challenge}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Preprocessing}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}String tokenization}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Replacing irrelevant words}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Stop words}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Simple vectorization}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Tokenizing}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}One-hot encoding}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}word2vec}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Skip-gram}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Forward}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Backward}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Training}{8}}
\@writefile{toc}{\contentsline {paragraph}{Positive sampling}{8}}
\@writefile{toc}{\contentsline {paragraph}{Negative sampling}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces t-SNE visualization of \emph  {word2vec} model on EN dataset\relax }}{9}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:word2vec}{{1}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5}Visualization}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6}Inference}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Recurrent neural network (RNN)}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Forward}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces RNN\relax }}{10}}
\newlabel{fig:rnn}{{2}{10}}
\newlabel{eqn:forward-all}{{5.6}{10}}
\newlabel{eqn:forward-h}{{5.7}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}Backward}{11}}
\@writefile{toc}{\contentsline {paragraph}{Output layer}{11}}
\newlabel{eqn:backward-o}{{5.8}{11}}
\newlabel{eqn:backward-c}{{5.9}{11}}
\newlabel{eqn:backward-V}{{5.10}{11}}
\@writefile{toc}{\contentsline {paragraph}{Hidden layer}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Computational graph showing gradients for $\bm  {h}^{(n)}$\relax }}{11}}
\newlabel{fig:grad-hn}{{3}{11}}
\newlabel{eqn:backward-hn}{{5.11}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Computational graph showing gradients for $\bm  {h}^{(t)}$\relax }}{12}}
\newlabel{fig:grad-ht}{{4}{12}}
\newlabel{eqn:backward-ht}{{5.12}{12}}
\newlabel{eqn:backward-b}{{5.13}{13}}
\newlabel{eqn:backward-W}{{5.14}{13}}
\newlabel{eqn:backward-U}{{5.15}{13}}
\@writefile{toc}{\contentsline {paragraph}{Summary}{14}}
\newlabel{eqn:backward-all}{{5.16}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Multilayer perceptron (MLP)}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}Forward}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces MLP computational graph\relax }}{14}}
\newlabel{fig:mlp}{{5}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Backward}{14}}
\@writefile{toc}{\contentsline {paragraph}{Output layer}{14}}
\@writefile{toc}{\contentsline {paragraph}{Second hidden layer}{15}}
\@writefile{toc}{\contentsline {paragraph}{First hidden layer}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Training}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.1}Weight initialization}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.2}Batch updates}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Training loss against epochs\relax }}{16}}
\newlabel{fig:batch-updates}{{6}{16}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Before batch updates}}}{16}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {After batch updates}}}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.3}Optimizers}{16}}
\@writefile{toc}{\contentsline {paragraph}{Stochastic gradient descent}{16}}
\@writefile{toc}{\contentsline {paragraph}{Adagrad}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.4}Regularization}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Distribution of labels in FR dataset\relax }}{17}}
\newlabel{fig:class-labels}{{7}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.5}Class weighting}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.6}Hyperparameter optimization}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Hyperparameter Selection\relax }}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Results}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.7.1}RNN}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces RNN Results\relax }}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.7.2}MLP}{18}}
\newlabel{table:mlpresults}{{\caption@xref {table:mlpresults}{ on input line 873}}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces MLP Results\relax }}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Evaluation}{18}}
